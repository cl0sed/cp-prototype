import os
import sys
import asyncio
import logging

from logging.config import fileConfig

from sqlalchemy.ext.asyncio import create_async_engine

from alembic import context
from alembic.operations import ops  # Import operations module

logger = logging.getLogger(__name__)  # Added logger instance

# --- Project-specific Setup ---
# Add the 'backend' directory to sys.path to allow importing 'app' package
sys.path.insert(
    0, os.path.realpath(os.path.join(os.path.dirname(__file__), "..", "..", ".."))
)

try:
    from app.db.models import Base
    from app.config import get_settings
except ImportError as e:
    logger.error(
        f"FATAL: Could not import Base or settings in Alembic env.py. Ensure backend/app/db/models.py defines 'Base', backend/app/config.py defines 'settings', and the script is run from the project root or paths are correct. Import Error: {e}"
    )  # Replaced prints with single logging call
    sys.exit(1)  # Stop if essential imports fail

# --- Alembic Configuration ---
config = context.config

# Interpret the config file for Python logging.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

logger = logging.getLogger(__name__)  # Added logger instance

# Set target metadata for 'autogenerate' support
target_metadata = Base.metadata


# --- Custom Autogenerate Directives Processing ---


def process_revision_directives(context, revision, directives):
    """
    Alembic hook to process revision directives before they are rendered.
    Used here to prepend the CREATE EXTENSION command for pgvector.
    """
    # Access the list of operations generated by autogenerate
    upgrade_ops = directives[0].upgrade_ops.ops

    # Prepend the CREATE EXTENSION command to the upgrade operations
    # Use ops.ExecuteSQLOp for a more formal representation
    upgrade_ops.insert(0, ops.ExecuteSQLOp("CREATE EXTENSION IF NOT EXISTS vector;"))

    # Downgrade doesn't need a corresponding drop extension unless specifically desired.


# --- Database URL Configuration ---
def get_url_from_settings():
    """Constructs the database URL from the application settings object."""
    try:
        # Assumes settings.DATABASE_URL is available (e.g., from .env)
        # Handles potential Pydantic SecretStr
        db_url = getattr(get_settings(), "DATABASE_URL", None)
        if db_url is None:
            raise ValueError(
                "DATABASE_URL not found in the settings object (app.config.settings). Check your .env file and config.py."
            )

        url_str = (
            db_url.get_secret_value()
            if hasattr(db_url, "get_secret_value")
            else str(db_url)
        )

        if not url_str:
            raise ValueError("DATABASE_URL is empty in the application settings.")
        return url_str
    except (AttributeError, ValueError) as e:
        logger.error(
            f"FATAL Error configuring database URL in Alembic env.py: {e}"
        )  # Replaced print with logging
        sys.exit(1)
    except Exception as e:
        logger.error(
            f"FATAL: An unexpected error occurred getting the database URL: {e}"
        )  # Replaced print with logging
        sys.exit(1)


# --- Migration Execution Functions ---
def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode."""
    url = get_url_from_settings()
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        # include_object=include_object # Add if using include_object filter
        process_revision_directives=process_revision_directives,  # Register the hook for offline mode
    )
    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection):
    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        # compare_type=True, # Optional: Check column types too
        # include_schemas=True, # If using schemas
        # include_object=include_object, # Add if using include_object filter
        process_revision_directives=process_revision_directives,  # Register the hook for online mode
    )
    with context.begin_transaction():
        context.run_migrations()


async def run_migrations_online_async() -> None:
    """Run migrations in 'online' mode using async engine."""
    # Get the database URL
    db_url = get_url_from_settings()

    # Create async engine
    connectable = create_async_engine(db_url)

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode."""
    asyncio.run(run_migrations_online_async())


# --- Main Execution Logic ---

# Configure context for offline or online mode
if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()

logger.info("Migrations execution finished.")  # Replaced print with logging

# The rest of the error handling remains the same
try:
    pass  # The main logic is now handled by the if/else above
except SystemExit:
    raise
except Exception as e:
    logger.error(
        f"FATAL: An error occurred during migration execution: {e}"
    )  # Replaced print with logging
    sys.exit(1)
